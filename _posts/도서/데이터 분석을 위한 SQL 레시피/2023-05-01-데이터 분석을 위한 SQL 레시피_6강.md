---
layout: post
title: 00.데이터 분석을 위한 SQL 레시피_6강
date: 2023-05-01 19:20:23 
category: book
---

# 데이터  

접근 분석 도구로 집계한 결과 또는 리포트도 어느 정도 필터링이 가능하지만, 제공되는 기능 이외의 리포트는 작성 불가.  

접근 분석 도구에서 제공되는 결과에서 추가로 복잡한 조건으로 드릴다운해 상세를 찾으려면 최저한의 상태로 집계할 항목을 추출해야함.   
이후 접근분석 도구에서 활용할 수 없는 업무 데이터와 조합하면 리포트 작성가능.  

### 이슈  
접근로그 데이터 14-3 그대로 사용   
구매로그 데이터 14-3-data.sql파일 purchase_log amout 전부 10000로 변경   

1) 1절 날짜별 방문자 수/ 방문 횟수/ 페이지 뷰 집계하기    
목적: 1회 방문당 페이지 뷰를 날짜별로 집계하기.   

웹사이트의 기본은 방문자 수, 방문 횟수, 페이지 뷰 집계  
-방문자 수: 브라우저를 꺼도 사라지지 않는 쿠키의 유니크 수  
            ex)한 명의 사용자가 1일에 3회 사이트를 방문해도 1회로 집계  
-방문 횟수: 브라우저를 껐을 때 사라지는 쿠키의 유니크 수  
            ex)한 명의 사용자가 1일에 3회 사이트를 방문하면 3회로 집계  
-페이지 뷰: 페이지를 출력한 로그의 줄 수  

```
# 날짜별 접근 데이터를 집계하는 쿼리
/*
과정
access_users : 각 날짜별 unique한 long session 수(하루 기준 사용자별 조회 유무/ 이하 방문자 수) 
access_count : 각 날짜별 unique한 short session 수(하루 기준 사용자별 전체조회 수/ 이하 방문 횟수)
page_view : 각 일별 전체 조회 수
pv_per_user: 페이지 뷰 / 방문자 수(하루 기준 인당 평균 조회 수)
*/
SELECT
  -- PostgreSQL, Hive, Redshift, SparkSQL, subString으로 날짜 부분 추출
  substring(stamp, 1, 10) as dt
  -- PostgreSQL, Hive, BigQuery, SparkSQL, substr 사용
  --, substr(stamp, 1, 10) AS dt
  -- 쿠키 계산하기
  , COUNT(DISTINCT long_session) AS access_users
  -- 방문 횟수 계산
  , COUNT(DISTINCT short_session) AS access_count
  -- 페이지 뷰 계산
  , COUNT(*) AS page_view

  -- 1인당 페이지 뷰 수
  -- PostgreSQL, Redshift, BigQuery, SparkSQL, NULLIF 함수 사용
  , 1.0 * COUNT(*) / NULLIF(COUNT(DISTINCT long_session), 0) AS pv_per_user

FROM
  access_log
GROUP BY
  -- PostgreSQL, Redshift, BigQuery
  -- SELECT 구문에서 정의나 별칭을 GROUP BY에 지정할 수 있음
  dt
  -- PostgreSQL, Hive, Redshift, SparkSQL
  -- SELECT 구문에서 별칭을 지정하기 이전의 식을 GROUP BY에 지정할 수 있음
  --substring(stamp, 1, 10)
ORDER BY dt;
```  
![14-1 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-1.PNG)  

2) 페이지 별 쿠키/ 방문 횟수/ 페이지 뷰 집계하기  
URL을 집계하면 각 페이지의 방문 횟수, 페이지 뷰 등을 집계할 수 있음.  
하지만 URL에는 매개변수, 광고 계측을 위한 매계변수 등이 포함되는 경우가 많음. 
따라서 한 페이지를 가리키는 여러 URL이 존재해 단순한 방법으로는 페이지 뷰를 제대로 구하기 힘듦.  
```  
# URL 별로 집계하기
SELECT
  url
  , COUNT(DISTINCT short_session) AS access_count
  , COUNT(DISTINCT long_session) AS access_users
  , COUNT(*) AS page_view
FROM
  access_log
GROUP BY
  url
;
```  
![14-2 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-2.PNG)  

```
# 경로별로 집계하기
/*
SQL의 출력 결과에는 URL 요청 매개변수가 포함됨.  
'/detail?id=**'를 상세 페이지라고 집계할 수 있게 요청 매개변수를 생략하고 경로만으로 집계.

정규표현식
//[^/]+([^?#]+)

대괄호 바깥 //: 슬래시 두개로 시작하는 패턴
[^/]: 슬래시 하나를 제외한 모든 문자가 하나 이상 반복되는 패턴, 
       [^] 대괄호 안의 캐럿 다음에 오는 문자 외의 문자 중 하나를 추출하는 패턴  
+: +바로 앞에 있는 문자가 한번 혹은 한번 이상 반복되는 패턴 
*/

//로 시작하면서 /를 제외한 문자로 시작하며 이후에 ?나 #으로 시작하지 않는 
WITH
access_log_with_path AS (
  -- URL에서 경로 추출
  select *
    -- PostgreSQL의 경우, 정규 표현식으로 경로 부분 추출
    ,substring(url from '//[^/]+([^?#]+)') AS url_path
  FROM access_log
)
SELECT
  url_path
  , COUNT(DISTINCT short_session) AS access_count
  , COUNT(DISTINCT long_session) AS access_users
  , COUNT(*) AS page_view
FROM
  access_log_with_path
GROUP BY
  url_path
;
```
![14-3 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-3.PNG)  
!!!!!!14-2_1 결과와 비교해서 해석해볼 것  

```
# URL에 의미를 부여해서 집계하기 
/*
기존 결과를 보면 /list/cd 혹은 /list/dvd 등의 리스트 페이지가 카테고리 별로 나뉘어짐을 볼 수 있음.
이를 카테고리/리스트 레이지로 묶어봄.
이 때 /list/newly/는 신상품 리스트 페이지로 취급.

이슈: COUNT(*) AS page_view라고 수정해야 함.

split_part(대상컬럼, '구분자', n)
대상컬럼을 구분자 기준으로 잘라서 n번째 문자 반환 

*/
WITH
access_log_with_path AS (
  -- URL에서 경로 추출
  SELECT *
    -- PostgreSQL의 경우, 정규 표현식으로 경로 부분 추출
    ,substring(url from '//[^/]+([^?#]+)') AS url_path
  FROM access_log
  )
,access_log_with_split_path AS (
  -- 경로의 첫 번째 요소와 두 번째 요소 추출하기
  SELECT *
    -- PostgreSQL, Redshift, split_part로 n번째 요소 추출하기
    , split_part(url_path, '/', 2) AS path1
    , split_part(url_path, '/', 3) AS path2
  FROM access_log_with_path
)
,access_log_with_page_name AS (
  -- 경로를 /로 분할하고, 조건에 따라 페이지 이름 붙이기
  SELECT *
  , CASE
      WHEN path1 = 'list' THEN
        CASE
          WHEN path2 = 'newly' THEN 'newly_list'
          ELSE 'category_list'
        END
      -- 이외의 경우에는 경로 그대로 사용
      ELSE url_path
    END AS page_name
  FROM access_log_with_split_path
)
SELECT
  page_name
  , COUNT(DISTINCT short_session) AS access_count
  , COUNT(DISTINCT long_session) AS access_users
  , COUNT(*) AS page_view
FROM access_log_with_page_name
GROUP BY page_name
ORDER BY page_name
;
```  
![14-4 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-4.PNG)  

유입원별로 방문횟수 또는 CVR 집계하기  

- 전환율(conversion rate, 다른 말로 컨버전율, 전환률 이하 CVR)  
    웹사이트를 방문한 사람 중, 소정의 유도된 행위를 한 방문자의 비율.   유도된 행위란, 예를 들면, 무언가를 구매한다든가 사이트의 핵심 문서를 읽는다든가, 무언가를 다운로드받는다든가 하는 행위를 의미.  
    전환율은 전환수를 방문자수로 나누어 계산. 보통 퍼센티지 단위 사용.  

- 웹사이트 접근 시 유입경로    
    검색엔진  
    검색 연동형 광고  
    트위터, 페이스북 등의 소셜미디어  
    제휴 사이트  
    광고 네트워크  
    다른 웹사이트에 붙은 링크(블로그 소개 기사 등)  

유입경로 별로 집계하면 웹사이트의 방문자가 어떤 행동을 해서 우리 웹사이트에 방문하는지 알 수 있음.  
추가로 검색 연동형 광고, 제휴, 광고 네트워크 등을 관리하는 마케팅 부문의 효과를 시각적으로도 활용 가능.  

유입원 판정  
레퍼러(referer) : 직전 페이지의 URL  
URL 매개변수 기반 URL 판정에 사용가능  
레퍼러 도메인과 랜딩 페이지를 사용한 URL 판정에 사용가능  

URL 매개변수 기반 판정  
광고가 어느정도 널리 퍼졌는지 집계하기 위해 URL에 광고 계측 전용 매개변수 설정.  
구글 애널리틱스는 URL 생성 도구로 만들어지는 매개변수를 사용해 유입수 리포트 기능 제공.  

구글 애널리틱스 설명  
URL 생성 도구 'Campaign URL Builder를 사용해 웹사이트의 URL 또는  
Campaign source 등 필요한 매개변수를 입력하면 URL을 생성해줌.  

ex)www.~~~.com?utm_source=google&utm_medium=cp&utm_compaign=spring_sale  

![구글 애널리틱스 설명](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/구글 애널리틱스 설명_1.PNG)  

URL 매개변수를 사용하면 다양한 유입계측 가능.  
검색엔진, 개인 블로그, 트위터처럼 광고 담당자가 조작할 수 없는 영역은 URL 매개변수 활용 불가능. 이 때에는 레퍼러를 사용해야함.  
전단지나 잡지등에 회사이름, 상품이름이 아닌 특징적인 어구를 넣어 이를 검색하게해 이벤트 사이트로 유도해 오프라인 광고 효과 계측 가능. 

해당 도메인이 자신의 사이트가 아니고 레퍼러(직전 페이지url)가 있는 경우  
두가지를 만족할 때 다음의 로직으로 유입원별 방문 횟수 집계  

![유입원 판단 로직](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/유입원 판단 로직.PNG)  

```
# 유입원별로 방문 횟수를 집계하는 쿼리

WITH
access_log_with_parse_info AS (
  -- 유입원 정보 추출하기
  SELECT *
    -- PostgreSQL, 정규 표현식으로 유입원 정보 추출하기
    , substring(url from 'https?://([^/]*)') AS url_domain
    , substring(url from 'utm_source=([^&]*)') AS url_utm_source
    , substring(url from 'utm_medium=([^&]*)') AS url_utm_medium
    , substring(referrer from 'https?://([^/]*)') AS referer_domain
  FROM access_log
)
, access_log_with_via_info AS (
  SELECT *
    , ROW_NUMBER() OVER(ORDER BY stamp) AS log_id
    , CASE
        WHEN url_utm_source <> '' AND url_utm_medium <> ''
          -- PostgreSQL, Hive, BigQuery, SpaerkSQL, concat 함수에 여러 매개변수 사용 가능
          --THEN concat(url_utm_source, '-', url_utm_medium) 이 코드로 수행해도 됨.
          -- PostgreSQL, Redshift, 문자열 결합에 ||(or) 연산자 사용
          THEN url_utm_source || '-' || url_utm_medium
        WHEN referer_domain IN ('search.yahoo.co.jp', 'www.google.co.jp') THEN 'search'
        WHEN referer_domain IN ('twitter.com', 'www.facebook.com') THEN 'social'
        ELSE 'other'
      -- ELSE referer_domain으로 변경하면, 도메인별 집계 가능
      END AS via
  FROM access_log_with_parse_info
  -- 레퍼러가 없는 경우와 우리 사이트 도메인의 경우 제외
  WHERE COALESCE(referer_domain, '') NOT IN ('', url_domain)
)
SELECT via, COUNT(1) AS access_count
FROM access_log_with_via_info
GROUP BY via
ORDER BY access_count DESC;
```
![14-5 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-5.PNG)  

유입원별로 CVR 집계하기   
WITH 구문의 access_log_with_purchase_amount 테이블을 수정하면 다양하게 사용가능  

```
# 각 방문에서 구매한 비율(CVR)을 집계하는 쿼리 
/*

*/

WITH
access_log_with_parse_info AS (
  -- 유입원 정보 추출하기
  SELECT *
    -- PostgreSQL, 정규 표현식으로 유입원 정보 추출하기
    , substring(url from 'https?://([^/]*)') AS url_domain
    , substring(url from 'utm_source=([^&]*)') AS url_utm_source
    , substring(url from 'utm_medium=([^&]*)') AS url_utm_medium
    , substring(referrer from 'https?://([^/]*)') AS referer_domain
  FROM access_log
)
, access_log_with_via_info AS (
  SELECT *
    , ROW_NUMBER() OVER(ORDER BY stamp) AS log_id
    , CASE
        WHEN url_utm_source <> '' AND url_utm_medium <> ''
          -- PostgreSQL, Hive, BigQuery, SpaerkSQL, concat 함수에 여러 매개변수 사용 가능
          --THEN concat(url_utm_source, '-', url_utm_medium) 이 코드로 수행해도 됨.
          -- PostgreSQL, Redshift, 문자열 결합에 ||(or) 연산자 사용
          THEN url_utm_source || '-' || url_utm_medium
        WHEN referer_domain IN ('search.yahoo.co.jp', 'www.google.co.jp') THEN 'search'
        WHEN referer_domain IN ('twitter.com', 'www.facebook.com') THEN 'social'
        ELSE 'other'
      -- ELSE referer_domain으로 변경하면, 도메인별 집계 가능
      END AS via
  FROM access_log_with_parse_info
  -- 레퍼러가 없는 경우와 우리 사이트 도메인의 경우 제외
  WHERE COALESCE(referer_domain, '') NOT IN ('', url_domain)
)
, access_log_with_purchase_amount AS (
  SELECT
    a.log_id
    , a.via
    , SUM(
        CASE
          -- PostgreSQL, interval 자료형의 데이터로 날짜와 시간 사칙연산 가능
          WHEN p.stamp::date BETWEEN a.stamp::date AND a.stamp::date + '1 day'::interval
            THEN amount
        END
      ) AS amount
  FROM
    access_log_with_via_info AS a
    LEFT OUTER JOIN
      purchase_log AS p
      ON a.long_session = p.long_session
  GROUP BY a.log_id, a.via
)
SELECT
  via
  , COUNT(1) AS via_count
  , count(amount) AS conversions
  , AVG(100.0 * SIGN(COALESCE(amount, 0))) AS cvr
  , SUM(COALESCE(amount, 0)) AS amount
  , AVG(1.0 * COALESCE(amount, 0)) AS avg_amount
FROM
  access_log_with_purchase_amount
GROUP BY via
ORDER BY cvr desc
;
```  
![14-6 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-6.PNG)  

접근 요일, 시간대 파악하기  

사용자가 접근하는 요일과 시간대는 서비스에 따라 특징이 있음.  
이런 특성을 파악하면 공지사항 또는 메일 매거진 발신 시점, 캠페인 시작 지점과 종료 시점 드을 검토할 때 활용 가능.  
외부 미디어에 대한 노출이 순간 증가했을 때, 공지사항 또는 메일 매거진을 전달하면 효과가 큼.  

과정  
1.24시간에서 추출하고자 하는 단위 결정(10분 간격, 15분 간격, 30분 간격 등)  
2.접근한 시간을 해당 단위로 집계하고, 요일과 함께 방문자 수를 집계  

요일 번호 정의는 미들웨어에 따라 다르니 주의  
![요일 번호 정의](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/요일 번호 정의.PNG)  
```
# 요일/시간대별 방문자 수를 집계하는 쿼리  
/*

현재코드 기준 30분 간격

WITH
access_log_with_dow AS (
  SELECT
    stamp
    -- 일요일(0)부터 토요일(6)까지의 요_일 번호 추출하기
    -- PostgreSQL, Redshift의 경우 date_part 함수 사용하기
    -- ::는 데이터 형식 변환
    , date_part('dow', stamp::timestamp) AS dow

    -- 00:00:00부터의 경과 시간을 초 단위로 계산
    -- PostgreSQL, Hive, Redshift, SparkSQL
    --  substring 함수를 사용해 시, 분, 초를 추출하고 초 단위로 환산하여 더하기
    -- BigQuery의 경우 substring을 substr, int를 int64로 수정하기
    , CAST(substring(stamp, 12, 2) AS int) * 60 * 60
      + CAST(substring(stamp, 15, 2) AS int) * 60
      + CAST(substring(stamp, 18, 2) AS int)
      AS whole_seconds
    
    -- 시간 간격 정하기
    -- 현재 예제에서는 30분(1800초)으로 지정하기
    , 30 * 60 AS interval_seconds
  FROM access_log
)
, access_log_with_floor_seconds AS (
  SELECT
    stamp
    , dow
    -- 00:00:00부터의 경과 시간을 interval_seconds로 나누기
    -- PostgreSQL, Hive, Redshift, SparkSQL의 경우는 다음과 같이 사용하기
    -- BigQuery의 경우 int를 int64로 수정하기
    , CAST((floor(whole_seconds / interval_seconds) * interval_seconds) AS int)
      AS floor_seconds
  FROM access_log_with_dow
)
, access_log_with_index AS (
  SELECT
    stamp
    , dow
    -- 초를 다시 타임스탬프 형식으로 변환하기
    -- PostgreSQL, Redshift의 경우는 다음과 같이 하기
    , lpad(floor(floor_seconds / (60 * 60))::text, 2, '0') || ':'
        || lpad(floor(floor_seconds % (60 * 60) / 60)::text, 2, '0') || ':'
        || lpad(floor(floor_seconds % 60)::text, 2, '0')
        AS index_time
  FROM access_log_with_floor_seconds
)
SELECT
  index_time
  , COUNT(CASE dow WHEN 0 THEN 1 END) AS sun
  , COUNT(CASE dow WHEN 1 THEN 1 END) AS mon
  , COUNT(CASE dow WHEN 2 THEN 1 END) AS tue
  , COUNT(CASE dow WHEN 3 THEN 1 END) AS wed
  , COUNT(CASE dow WHEN 4 THEN 1 END) AS thu
  , COUNT(CASE dow WHEN 5 THEN 1 END) AS fri
  , COUNT(CASE dow WHEN 6 THEN 1 END) AS sat
FROM
  access_log_with_index
GROUP BY
  index_time
ORDER BY
  index_time
;
*/
```  
![14-7 결과](https://github.com/shina1221/shina1221.github.io/blob/main/_posts/%EB%8F%84%EC%84%9C/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20SQL%20%EB%A0%88%EC%8B%9C%ED%94%BC/img/14-7.PNG)  

사용자 방문이 많은 시간대에 캠페인을 실시하는 것이 안정적  
사용자 방문이 적은 시간대에 전자상거래 사이트의 경우 타임세일,  
                            소셜게임같은 경우 아이템 확득 상승 등의 이벤트 검토  

#출처  
위키백과  
[데이터 분석가 도전기](https://mjrecord.tistory.com/m/12)  
[Interactive Developer](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=rookiemodel&logNo=10139446205)  
[위키백과](https://ko.wikipedia.org/wiki/%EC%A0%84%ED%99%98%EC%9C%A8)  
[저자 github](https://github.com/Wshid/sql_recipe/blob/master/06.%EC%9B%B9%EC%82%AC%EC%9D%B4%ED%8A%B8%EC%97%90%EC%84%9C%EC%9D%98_%ED%96%89%EB%8F%99%EC%9D%84_%ED%8C%8C%EC%95%85%ED%95%98%EB%8A%94_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%B6%94%EC%B6%9C/%5BCHAP.14%5D%EC%82%AC%EC%9D%B4%ED%8A%B8_%EC%A0%84%EC%B2%B4%EC%9D%98_%ED%8A%B9%EC%A7%95_%EA%B2%BD%ED%96%A5_%EC%B0%BE%EA%B8%B0.md)  
