---
layout: post
title: 분산분석
date: 2023-08-29 19:21:23 +0900
category: statistics 
use_math: true
---
# 비전공자를 위한 통계방법론    
> 분산분석의 원리    

세 개 이상의 모집단 평균에 유의한 차이가 존재하는지 여부를 검증하기 위해선   
분산분석(ANOVA)을 활용한다.  
분산분석은 명칭과는 다르게 복수의 모집단 평균 사이에 유의한 차이가 존재하는지 여부를  
검증하는 방법론이다.
<br>  
비교하고자 하는 복수의 모집단 평균에 유의한 차이가 존재하는지 여부를 검증할 땐  
해당 모집단들의 평균이 모두 같다는 귀무가설을 설정한다.
<br>  
**대립가설: 비교대상인 모집단들의 평균은 모두 같지 않을 것이다.**  
복수의 모집단들 평균에 유의한 차이가 존재하는지 여부를 확인하려면  
각 모집단들로부터 표본을 확보하고 그 표본들로부터 얻은 표본평균값들 사이에  
얼마나 큰 차이가 존재하는지 확인하면 될 것이다.
<br>  
**표본평균값들 사이의 차이는 표본평균값들이 그것들의 기대값(=표본분포의 중앙값)으로부터**  
**얼마나 흩어져 있는지를 나타내는 분산에 의해 가늠되어 분산분석이라는 명칭이 붙는다.**
<br>  
분산분석의 기본가정  
1.집단 내 개체들의 값의 분포는 정규분포의 특성을 갖는다.  
2.비교대상 k개 집단 내 개체들의 분산은 모두 동일하다.  $\sigma_1^2=\sigma_2^2=\sigma_k^2$  
3.집단들이 서로 독립적이다.
<br>  
**분산분석의 핵심질문**  
각 표본에서 얻은 표본평균들이 서로 다른 것은 평균이 서로 다른 모집단들에서 뽑혔기  
때문인가, 아니면 모집단의 평균은 서로 다르지 않은데 표본 추출과정에서 우연적 요소  
때문에 다른 값을 갖게 된 것인가?  
<br>  
검증통계량 F = 표본간분산/표본내분산  
분자의 자유도는 k(그룹 수)-1이고, 분모의 자유도는 $n_T-k$이다.  
$n_T$는 k개의 모집단으로 부터 추출된 모든 표본에 속한 개체들의 총 수이다.
<br>  
검증통계치 F값이 유의수준 a에서 F분포상의 기각영역 경계값 $F_{\alpha,k-1,n_T-k}$보다  
크거나 같으면 혹은 작거나 같으면 귀무가설을 기각한다.
<br>  
> 표본간분산과 표본내분산 간 비율이 왜 복수의 모집단들 간 평균 차이를 검증하기 위한  
검증통계량이 될 수 있을까?  

네 개의 모집단 내 개체들의 분산이 모두 $\sigma^2$로 동일하다고 가정하에  
네 개의 모집단의 공통분산($\sigma^2$)을 네 개의 표본데이터에서 얻은 표본분산을 가지고  
추정하는 방식이 두가지 있다.  
**1.네 개의 표본분산의 산술평균으로 추정하는 방식**  
-네 개의 표본 각각에서 얻은 네 개의 분산값 ($s_1^2,s_2^2,s_3^2,s_4^2$) 모두  
모집단들의 공통분산$\sigma^2$에 대한 점추정치라고 볼 수 있기 때문에 그 표본분산값들의  
**산술평균이 곧 네 모집단의 공통분산에 대한 통합적 점추정치로 볼 수 있다.**  
**이 점추정치는 네 개의 개별 표본에 포함된 개체들의 Y값 분산을 대표하기 때문에**  
**표본내분산이라고 불린다.**  
이런 표본내분산은 네 개의 표본이 동일한 분산을 갖고 있는 모집단으로부터 뽑힌  
표본들이기 때문에 표집과정에서 개별 표본안에 어떤 개체들이 포함되느냐에 따라 분산간에  
약간의 차이가 발생할 수는 있지만, 그 외 다른 요인에 의해 체계적으로 네 개의 표본분산  
사이에 차이가 발생한다고 볼 수는 없다.
<br>  
**2.표본평균의 이론적 표본오차 공식 $s_{\overline{y}}=\sigma/\sqrt{n}$을 활용해 추정하는 방식**  
-이를 집단의 분산($\sigma^2$)를 기준으로 재정리하면 $\sigma^2=n\cdot s_{\overline{y}}^2$가 된다.  
여기서 표본평균의 표본오차 $s_{\overline{y}}$을 봤을 때  
만약 앞에서 설정한 귀무가설이 옳다면 네개의 표본평균은 개념적으로 공통의 모집단 평균을 기대값(확률분포의 중앙값)으로 하고 정규분포의 모양을 한 표본평균의 표본분포로  
부터 무작위로 뽑힌 네 개의 표본평균값이라고 할 수 있다.  
여기서 구한 표본평균 $s_1^2,s_2^2,s_3^2,s_4^2$의 분산 $s_{\overline{y}}^2$은  
표본평균들이 모집단 평균(여기서는 표본평균들의 평균이 모집단 평균의 대응치)을   
중심으로 흩어져 있는 정보를 반영하고 있어 **집단간분산**이라고 한다.  
ex) 4개의 표본집단, 각 표본집단들의 표본평균(3,4,7,6)의 평균 5  
$s_{\overline{y}} = \sqrt{\frac{(3-5)^2+(4-5)^2+(7-5)^2+(6-5)^2}{4-1}}$
<br>  
귀무가설이 옳다면 네 개의 표본평균 값들이 공통의 모집단 평균$\mu$로 부터 멀리 떨어진  
값을 가질 확률이 낮을 것이기 때문에 표본간분산도 크지 않을 것이다.
<br>  
분자에 해당하는 표본간분산은 귀무가설이나 대립가설 중 어느것이 옳으냐에 따라 변하는 지표다.  
귀무가설이 옳을 때는 표본내분산에 비해 그 값이 클 이유가 없지만 모집단간 평균 차이가  
커지면 커질수록(대립가설이 옳을 조건이 더 강해질수록) 그 값은 더 커진다.  
따라서 두 분산의 비율로 표시되는 검증통계량 값이 커질수록 귀무가설이 옳다는 전제하에  
그려진 표본분포상에서 그 값이 나올 확률이 낮기 때문에 대립가설을 채택할 가능성이  
높아진다.
<br>  
#표본내분산과 표본간분산  
표본내분산은 표집과정에서 개별 표본에 어떤 개체들이 포함되느냐에 따라 표본들 사이에  
약간의 차이가 있을 수는 있지만 귀무가설과 대립가설 중 어느 것이 옳은지에 따라  
그 크기가 크게 영향을 받지 않는다.  
하지만 **표본간분산은** 모집단들 간 평균 차이가 없을 경우에는 그 크기가 표본내분산과  
별다른 차이가 없겠지만 **모집단들 간 평균 차이가 커질수록 각 모집단에서 추출한 표본들의**  
**평균값 차이도 커질 것이기 때문에 표본간분산의 크기가 표본내 분산에 비해 점점 더 커질 것이다.**  
이런 특성차이로 인해 **통계검증량 F는 표본간분산/표본내분산**이 사용된다.  
표본내분산에 비해 표본간분산이 커질수록 검정통계량의 값이 커지고,  
귀무가설이 옳다는 조건하에서 그 값이 나올 확률은 점점 더 작아질 것이다.  
따라서 그만큼 귀무가설을 기각할 확률이 높아진다.
<br>  
**귀무가설을 기각할지 여부를 결정하는 것은 표본간분산이다.**  
차이가 크면 클 수록 표본평균들이 동일한 모집단에서 뽑혔다기보다 평균값이 다른  
모집단들로부터 뽑혀 나왔을 가능성이 높다고 볼 수 있기 때문이다.
<br>  
그런데 표본평균의 분산은 변수를 측정한 척도의 단위에 따라 그 값의 크기가 큰 차이를  
보인다. 이럴 경우 측정단위에 따른 차이를 제거해줄 필요가 있는데 그 과정이 일종의  
표준화로 볼 수 있다.(정규분포에서 관측치가 평균으로부터 얼마나 떨어져 있는지를  
표준화된 단위로 나타내기 위해 관측치에서 평균을 뺀 후 표준편차로 나눠줬던 표준화를  
상기해볼 것)
<br>  
**표본간분산을 표본내분산으로 나눠줌으로써 측정단위에 따른 표본분산간의 크기가**  
**달라지는 효과를 제거할 수 있다.**  
**검증통계량은 표본간분산을 표본내분산으로 표준화한 값이라고 볼 수 있다.**      

