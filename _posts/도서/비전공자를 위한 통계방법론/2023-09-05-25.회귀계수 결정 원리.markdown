---
layout: post
title: 회귀계수 결정 원리   
date: 2023-09-05 20:21:23 +0900
category: statistics 
use_math: true
---
# 비전공자를 위한 통계방법론    
> 회귀계수 결정 원리: 최소제곱 원리  

회귀분석은 연구자가 관심을 가지고 있는 특정 변수 Y에 변수 X가 통계적으로 유의미한  
영향을 미치는지 여부를 확인하는데 사용하는 통계분석기법이다.  
선형적(1차)관계 이외에도 2차,3차 함수 같은 비선형적 관계를 규명하는데도 유용하다.  
확정형 모형: $Y=a+b \cdot X_i$처럼 X 값이 정해지면 Y값도 정해지는 함수식이다.  
체계적 부분이라고도 한다.  
비확정형 모형: $Y=a+b \cdot X_i+e_i$처럼 X값이 정해져도 Y깂이 정해지지 않는 함수식이다. 확률적부분이라고도 한다.   
오차항($e_i$): 잔차라고도 하며 i번째 개체의 X값이 주어졌을 때 $a+b \cdot X_i$에 의해  
정해지는 Y값과로 i번째 개체의 실제 Y값($Y_i$)사이의 차이를 의미한다.   
회귀모형에서 a는 X=0일 때의 Y값이고, 계수 b는 변수 X와 Y사이에 존재하는 관계의  
크기와 방향을 나타내는 계수이다.  
  
오차항을 포함하는 비확정형 모형으로 X와 Y관계가 표시될 때 이를 회귀모형이라고 한다.  
그리고 계수 a와 b값을 찾는 통계분석기법을 회귀분석이라고 한다.  
산포도: X와 Y좌표로 그려진 것이다.  
회귀선: 산포도가 보여주는 X와 Y의 관계를 보여주는 그래프이다.  
$\widehat{Y}_i$: i번째 개체의 Y값에 대한 예측치로 i번째 개체의 실제 Y값이 아닌  
회귀방정식에 의해 결정되는 Y값이다.  
  
> 상관계수와 회귀계수의 관계  

1차 함수로 표시되는 회귀방정식 $\widehat{Y}_i= a + b \cdot X_i$에서의 회귀계수 b와  
상관계수 $r_{xy}$사이에는 다음의 관계가 성립한다. 여기서 $s_x$와 $s_y$는 각각 변수  
X와 Y의 표본 표준편차이다.  
  
$b=r_{xy} \cdot \frac{s_y}{s_x}$ 혹은 $r_{xy}= b \cdot \frac{s_x}{s_y}$  
  
> 회귀계수 결정 원리: 최소제곱 원리  
  
X와 Y의 관계를 잘 나타내주는 회귀방정식의 계수 a와 b값을 파악하기 위해선  
개별 $Y_i$값들과 회귀선에 근거해 예측한 $\widehat{Y}_i$값들의 차이(오차(잔차))가  
최소가 되게 하는 회귀식을 최적선으로 정하는 방식을 생각해볼 수 있다.  
$e_i = Y_i - \widehat{Y}_i = Y_i - (a+b \cdot X_i)$  
  
이에 대한 대안으로 모든 오차(잔차)들의 절대값의 합이 최소가 되게 하는 회귀식을  
찾는 것이 있다. 여기서 오차들의 절대값의 합이 최소가 되게 하는 회귀식은 잔차제곱의  
합이 최소가 되게 하는 회귀식과 같아 일반적으로 최소제곱법이라고 한다.  

> 예측치와 회귀의 의미  

회귀분석에서는 오차의 기대값이 0이라는 것을 중요한 가정 중 하나로 삼고 있다.  
회귀분석에서 X값에 근거해 Y값을 예측할 때에는 동일한 X값을 갖는 개체들이 취할 수 있는 다양한 Y값들 중에서 어느 하나를 예측치로 제시하기보다는 동일한 X값을 갖는 개체들의  
Y값들의 기대값(평균)을 대표적인 예측치로 제시한다.  
즉 동일한 X값을 갖는 다양한 개체들의 Y값들을 하나의 대표값으로 회귀시켜 그것들의  
예측치로 제시한다.   
  
> 회귀모형을 결정계수($R^2$)  

제곱합의 개념을 회귀모형에 적용해보면 다음과 같다.  
분산분석의 원리를 원용하면 i번째 개체들의 Y관측치가 다음과 같이 표현된다.  
$y_i = \overline{y} + (\widehat{y}_i - \overline{y}) + (y_i - \widehat{y}_i)$  
이는 다음과 같이 재정렬된다.  
$y_i - \overline{y} = (\widehat{y}_i - \overline{y}) + (y_i - \widehat{y}_i)$  
  
이는 한 개체의 관측치가 Y의 총평균으로부터 떨어져있는 정도인 총편차 ($y_i -\overline{y}$)는  
회귀방정식에 기반한 해당개체의 Y값 예측치가 총평균으로부터 떨어져 있는 정도를 나타낸  
회귀편차($\widehat{y}_i - \overline{y}$)에 그 개체의 실제 Y값이 회귀방정식에 기반한  
예측치로부터 떨어져 있는 정도를 나타내는 잔차($y_i - \widehat{y}_i$, 오차)를 더한  
값과 같다는 의미이다. 즉 **총편차는 회귀편차와 잔차로 분해된다.**  

회귀편차: 총편차-원 관측치가 전체 평균값으로부터 떨어져 있는 정도 중에서  
회귀방정식을 사용해 예측(설명)가능해진 영역이다.  
잔차: 총편차 중에서 일정한 회귀방정식을 써도 여전히 예측(설명)되지 않는 부분이다.  

총제곱합(SST)는 회귀제곱합(SSR)과 오차제곱합(SSE)를 더한값과 같다.  
이는 분산분석에서 총제곱합(SST)가 표본간제곱합(SSB)와 표본내제곱합(SSW)를 더한  
것이라는 원리와 동일하다.  
  
$\sum_{i=1}^{n}(y_i-\overline{y})^2=\sum_{i=1}^{n}(\widehat{y}_i-\overline{y})^2+\sum_{i=1}^{n}(y_i-\widehat{y}_i)^2$  
총제곱합(SST) = 회귀제곱합(SSR) + 오차제곱합(SSE)  

**결정계수는 회귀모형의 예측력(설명력)이다.**  
**결정계수$R^2$는 총제곱합 중에서 회귀제곱합(SSR)이 차지하는 비율을 가리킨다.**  
**결정계수는 데이터에 속한 개체들의 값을 예측하는데 평균값을 사용할 때 예측(설명) 할**  
**수 없었던 총변량 중에서 특정 회귀방정식으로 예측(설명)가능하게 된 부분의 비율이다.**  
1에 가까울 수록 회귀방정식의 예측력이 높다고 볼 수 있다.  
$R^2 = \frac{SSR}{SST}, (0\leq R^2 \leq1)$  
  
독립변수 X와 종속변수 Y 사이의 관계를 보여주는 회귀방정식을 사용하지 않은 채  
데이터에 속한 특정 개체 i의 Y값($y_i$)을 예측하라고 하면 개체들의 총평균($\overline{y}$)으로 예측할 수 밖에 없고, 그 경우 오차가 매우 클 것이다.  
하지만 회귀방적식과 해당 개체의 X값($x_i$)에 대한 정보를 주고 그 개체의 Y값을  
예측하라고 하면 회귀예측치$\widehat{y}_i$로 예측할 것이기 때문에 그만큼 정확도,  
혹은 예측력(설명력)이 높아질 것이다.  
회귀방정식을 사용하지 않은채 총평균으로 표본에 속한 특정 개체의 Y값을 예측하면 해당  
개체의 Y값과 총평균 사이의 편차(총편차)만큼의 오차가 남아있지만,  
회귀방정식을 하용해 회귀예측치로 해당 개체의 Y값을 예측하면 총편차 중에서  
회귀편차만큼 오차가 줄어들게 되고 나머지 잔차만큼만 오차로 남게된다.  
  
> 결정계수와 상관계수의 관계  

독립변수가 한 개인 단순회귀 모형 $Y_i = a+b\cdot X_i + e_i$의 결정계수($R^2$)는 X와  
Y간 상관계수($r_{xy}$)와 다음의 관계가 성립한다.  
$R^2 = r^2_{xy}$