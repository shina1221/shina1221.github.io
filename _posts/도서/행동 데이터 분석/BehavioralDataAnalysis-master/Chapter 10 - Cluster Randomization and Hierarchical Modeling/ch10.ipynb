{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decent-playback",
   "metadata": {},
   "source": [
    "# Chapter 10: Cluster Randomization and Hierarchical Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-skirt",
   "metadata": {},
   "source": [
    "# Libraries and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-running",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import seaborn as sns\n",
    "\n",
    "# Chapter-specific libraries\n",
    "# To rescale numeric variables\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# To one-hot encode cat. variables\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-michigan",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standing-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data_df = pd.read_csv('chap10-historical_data.csv')\n",
    "exp_data_df = pd.read_csv('chap10-experimental_data.csv')\n",
    "\n",
    "#Shifting center_ID to distinguish it from indices\n",
    "hist_data_df['center_ID'] = hist_data_df['center_ID'] + 100 \n",
    "exp_data_df['center_ID'] = exp_data_df['center_ID'] + 100 \n",
    "\n",
    "#Removing the variable M6Spend we won't use in this chapter\n",
    "del(hist_data_df['M6Spend'])\n",
    "del(exp_data_df['M6Spend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-workshop",
   "metadata": {},
   "source": [
    "# Introduction to hierarchical modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surface-occasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:              MixedLM Dependent Variable: call_CSAT    \n",
      "No. Observations:   695205  Method:             REML         \n",
      "No. Groups:         10      Scale:              1.1217       \n",
      "Min. group size:    54203   Log-Likelihood:     -1026427.7247\n",
      "Max. group size:    79250   Converged:          Yes          \n",
      "Mean group size:    69520.5                                  \n",
      "-------------------------------------------------------------\n",
      "                   Coef. Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept          3.899    0.335  11.641 0.000  3.243  4.556\n",
      "reason[T.property] 0.199    0.003  74.786 0.000  0.194  0.205\n",
      "age                0.020    0.000 176.747 0.000  0.020  0.020\n",
      "Group Var          1.122    0.407                            \n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical analysis of historical data with center ID only as clustering variable\n",
    "mixed = smf.mixedlm(\"call_CSAT ~ reason + age\", data = hist_data_df, \n",
    "                   groups = hist_data_df[\"center_ID\"])\n",
    "print(mixed.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "macro-relationship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Mixed Linear Model Regression Results\n",
      "=============================================================\n",
      "Model:             MixedLM  Dependent Variable:  call_CSAT   \n",
      "No. Observations:  695205   Method:              REML        \n",
      "No. Groups:        10       Scale:               0.3904      \n",
      "Min. group size:   54203    Log-Likelihood:      -660424.9323\n",
      "Max. group size:   79250    Converged:           Yes         \n",
      "Mean group size:   69520.5                                   \n",
      "-------------------------------------------------------------\n",
      "                   Coef. Std.Err.    z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------------\n",
      "Intercept          3.901    0.367  10.639 0.000  3.182  4.620\n",
      "reason[T.property] 0.200    0.002 126.789 0.000  0.196  0.203\n",
      "age                0.020    0.000 298.302 0.000  0.020  0.020\n",
      "Group Var          1.304    0.976                            \n",
      "rep_ID Var         0.776    0.131                            \n",
      "=============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical analysis of historical data with center ID and rep ID as clustering variable\n",
    "vcf = {\"rep_ID\": \"0+C(rep_ID)\"}\n",
    "mixed2 = smf.mixedlm(\"call_CSAT ~ reason + age\", \n",
    "                    data = hist_data_df, \n",
    "                    groups = hist_data_df[\"center_ID\"],\n",
    "                    re_formula='1',\n",
    "                    vc_formula=vcf)\n",
    "print(mixed2.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-print",
   "metadata": {},
   "source": [
    "# Determining random assignment and sample size/power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "circular-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for simulation\n",
    "\n",
    "def hlm_metric_fun(dat_df):\n",
    "    vcf = {\"rep_ID\": \"0+C(rep_ID)\"}\n",
    "    h_mod = smf.mixedlm(\"call_CSAT ~ reason + age + group\", \n",
    "                    data = dat_df, \n",
    "                    groups = dat_df[\"center_ID\"],\n",
    "                    re_formula='1',\n",
    "                    vc_formula=vcf)\n",
    "    coeff = h_mod.fit().fe_params.values[2]\n",
    "    return coeff\n",
    "\n",
    "def boot_CI_fun(dat_df, metric_fun = hlm_metric_fun, B = 20, conf_level = 9/10):\n",
    "    Ncalls_rep = 1200\n",
    "    coeff_boot = []\n",
    "    # Calculate coeff of interest for each simulation\n",
    "    for b in range(B):\n",
    "        boot_df = dat_df.groupby(\"rep_ID\").sample(n=Ncalls_rep,\n",
    "                                                  replace=True).\\\n",
    "        reset_index(drop= True)\n",
    "        coeff = metric_fun(boot_df)\n",
    "        coeff_boot.append(coeff)\n",
    "    #Extract confidence interval\n",
    "    coeff_boot.sort()\n",
    "    offset = round(B * (1 - conf_level) / 2)\n",
    "    confint = [coeff_boot[offset], coeff_boot[-(offset+1)]]\n",
    "    return confint\n",
    "\n",
    "def decision_fun(dat_df, metric_fun, B = 20, conf_level = 0.9):\n",
    "    boot_CI = boot_CI_fun(dat_df, metric_fun, B = B, conf_level = conf_level)\n",
    "    decision = 1 if boot_CI[0] > 0  else 0\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-moscow",
   "metadata": {},
   "source": [
    "## Random assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2572810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nreps</th>\n",
       "      <th>avg_call_CSAT</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>pct_reason_pmt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>center_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.664430</td>\n",
       "      <td>39.962880</td>\n",
       "      <td>0.601027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>21.0</td>\n",
       "      <td>3.958169</td>\n",
       "      <td>39.959532</td>\n",
       "      <td>0.599237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4.030376</td>\n",
       "      <td>39.981830</td>\n",
       "      <td>0.599508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>15.0</td>\n",
       "      <td>5.296561</td>\n",
       "      <td>40.063354</td>\n",
       "      <td>0.599690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>21.0</td>\n",
       "      <td>5.921405</td>\n",
       "      <td>39.977681</td>\n",
       "      <td>0.600679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nreps  avg_call_CSAT    avg_age  pct_reason_pmt\n",
       "center_ID                                                 \n",
       "101         18.0       3.664430  39.962880        0.601027\n",
       "102         21.0       3.958169  39.959532        0.599237\n",
       "103         22.0       4.030376  39.981830        0.599508\n",
       "104         15.0       5.296561  40.063354        0.599690\n",
       "105         21.0       5.921405  39.977681        0.600679"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregating data to center level\n",
    "center_data_df = hist_data_df.groupby('center_ID').agg(\n",
    "        nreps = ('rep_ID', lambda x: x.nunique()),\n",
    "        avg_call_CSAT = (\"call_CSAT\", \"mean\"),\n",
    "        avg_age=(\"age\", \"mean\"),\n",
    "        pct_reason_pmt=('reason', \n",
    "                        lambda x: sum(1 if r=='payment' else 0 for r in x)/len(x))\n",
    "        )\n",
    "\n",
    "#Reformatting variables as needed\n",
    "center_data_df['nreps'] = center_data_df.nreps.astype(float)\n",
    "\n",
    "center_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entire-workstation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[102, 101],\n",
       "       [106, 103],\n",
       "       [107, 104],\n",
       "       [110, 105],\n",
       "       [109, 108]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Function to prep the data\n",
    "def strat_prep_fun(dat_df):\n",
    "\n",
    "    #Extracting components of the data\n",
    "    num_df = dat_df.copy().loc[:,dat_df.dtypes=='float64'] #Numeric vars\n",
    "    center_ID = [i for i in dat_df.index]\n",
    "\n",
    "    #Normalizing all numeric variables to [0,1]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(num_df)\n",
    "    num_np = scaler.transform(num_df)\n",
    "    \n",
    "    return center_ID, num_np\n",
    "    \n",
    "def pair_fun(dat_df, K = 2):\n",
    "    \n",
    "    match_len = K - 1 # Number of matches we want to find\n",
    "    match_idx = match_len - 1 # Accounting for 0-indexing\n",
    "    \n",
    "    center_ID, data_np = strat_prep_fun(dat_df)\n",
    "    N = len(data_np)\n",
    "    \n",
    "    #Calculate distance matrix\n",
    "    from scipy.spatial import distance_matrix\n",
    "    d_mat = distance_matrix(data_np, data_np)\n",
    "    np.fill_diagonal(d_mat,N+1)\n",
    "    # Set up variables\n",
    "    available = [i for i in range(N)]\n",
    "    available_temp = available.copy()\n",
    "    matches_lst = []\n",
    "    lim = int(N/match_len)\n",
    "    \n",
    "    closest = np.argpartition(d_mat, kth=match_idx,axis=1)\n",
    "    \n",
    "    for n in available:\n",
    "        if len(matches_lst) == lim: break\n",
    "        if n in available_temp:\n",
    "            for match_lim in range(match_idx,N-1):\n",
    "                possible_matches = closest[n,:match_lim].tolist()\n",
    "                matches = list(set(available_temp) & set(possible_matches))\n",
    "                if len(matches) == match_len:\n",
    "                    matches.append(n)\n",
    "                    matches_lst.append(matches)\n",
    "                    available_temp \\\n",
    "                    = [m for m in available_temp if m not in matches]\n",
    "                    break\n",
    "                else:\n",
    "                    closest[n,:] = np.argpartition(d_mat[n,:], kth=match_lim)\n",
    "    #Map center indices to their proper IDs\n",
    "    matches_id_lst = [[center_ID[k[0]],center_ID[k[1]]] for k in matches_lst]\n",
    "    return np.array(matches_id_lst)\n",
    "pair_fun(center_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-pride",
   "metadata": {},
   "source": [
    "## Power analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "national-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Simulation function #####\n",
    "def power_sim_fun(dat_df, metric_fun = hlm_metric_fun, Ncalls_rep = 1000, eff_size = 1, B = 20, conf_level = 0.9):\n",
    "    \n",
    "    #Extract the stratified pairs\n",
    "    stratified_pairs = stratified_assgnt_fun(dat_df, K=2)\n",
    "    Npairs = len(stratified_pairs)\n",
    "    Nperm = 2 ** Npairs\n",
    "    power_list = []\n",
    "    \n",
    "    for m in dat_df.month.unique():\n",
    "        #Sample down the data\n",
    "        sample_data_df = dat_df.loc[dat_df.month==m,]\n",
    "        sample_data_df = sample_data_df.groupby('rep_ID')\\\n",
    "        .sample(n=Ncalls_rep, replace=True)\\\n",
    "        .reset_index(drop = True)\n",
    "        for perm in range(Nperm):\n",
    "            bin_str = f'{perm:0{Npairs}b}'\n",
    "            idx = np.array([[i for i in range(Npairs)],\n",
    "                            [int(d) for d in bin_str]]).T\n",
    "            treat = [stratified_pairs[tuple(idx[i])] for i in range(Npairs)]\n",
    "            \n",
    "            sim_data_df = sample_data_df.copy()\n",
    "            sim_data_df['group'] = 'ctrl'\n",
    "            sim_data_df.loc[(sim_data_df.center_ID.isin(treat)),'group']\\\n",
    "                = 'treat'\n",
    "            \n",
    "            sim_data_df.loc[(sim_data_df.group=='treat'),'call_CSAT'] =\\\n",
    "                sim_data_df.loc[(sim_data_df.group=='treat'),'call_CSAT'] + eff_size\n",
    "                \n",
    "            sim_data_df.loc[(sim_data_df.call_CSAT > 10), 'call_CSAT'] = 10\n",
    "            \n",
    "            # Option 1: extract CIs for visualization\n",
    "            #sim_CI = boot_CI_fun(sim_data_df, lm_metric_fun)\n",
    "            #power_list.append(sim_CI)\n",
    "            \n",
    "            # Option 2: calculate decision for overall power determination\n",
    "            D = decision_fun(sim_data_df, metric_fun, B = B, conf_level = conf_level)\n",
    "            power_list.append(D)\n",
    "            \n",
    "    return power_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-carter",
   "metadata": {},
   "source": [
    "# Analyzing the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "metropolitan-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.477903237163797\n",
      "[0.4743435990678476, 0.48186949193475165]\n"
     ]
    }
   ],
   "source": [
    "##### Analysis of experimental data #####\n",
    "\n",
    "coeff = hlm_metric_fun(exp_data_df)\n",
    "print(coeff)\n",
    "\n",
    "hlm_CI = boot_CI_fun(exp_data_df, hlm_metric_fun)\n",
    "print(hlm_CI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
