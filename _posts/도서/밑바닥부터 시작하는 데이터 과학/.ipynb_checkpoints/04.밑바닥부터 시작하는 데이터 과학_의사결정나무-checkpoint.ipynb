{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 의사결정나무란?\n",
    "- 의사결정나무(decision tree): 다양한 의사결정 경로(decision path)와 결과(outcome)를 나타내는 데 나무 구조를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2. 엔트로피\n",
    "- 엔트로피(entropy): 얼마만큼의 정보를 담고 있는가\n",
    "- 엔트로피가 '무질서도(disorder)'를 의미한다는 말도 배운 적이 있을텐데 데이터의 '불확실성(uncertainty)'를 나타낼 때도 같은 표현을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "#처음 키를 지정할 때 값을 주지 않으면 해당 키에 대한 값을 디폴트 값을 지정\n",
    "#https://dongdongfather.tistory.com/69\n",
    "\n",
    "int_dict = defaultdict(int) #자료형 지정 set도 가능\n",
    "int_dict \n",
    "#설정값을 지정하지 않을 경우 키값은 0으로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'key': 0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int_dict['key'])\n",
    "int_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'key': 0, 'key2': 'test'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_dict['key2']='test'\n",
    "int_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "from functools import partial\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    '''클래스에 속할 확률을 입력하면 엔트로피를 계산하라'''\n",
    "    return sum(-p * math.log(p, 2)\n",
    "              for p in class_probabilities if p)  # 확률이 0인 경우는 제외함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터는 (input, label) 쌍으로 구성되어 있기 때문에, 각 클래스 레이블의 확률은 별도로 계산해 주어야 한다.\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "           for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3. 파티션의 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    '''subsets는 레이블이 있는 데이터의 list의 list이다.\n",
    "    그에 대한 파티션 엔트로피를 구하라.'''\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    \n",
    "    return sum(data_entropy(subset) * len(subset) / total_count\n",
    "              for subset in subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4. 의사결정나무 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},   False),\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},  False),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},     True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},  True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},    False),\n",
    "        ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},        True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'}, False),\n",
    "        ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'}, True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'yes'},    True),\n",
    "        ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 가장 낮은 엔트로피를 반환하는 파티션을 찾는다.\n",
    "# def group_by(items, key_fn):\n",
    "#     \"\"\"returns a defaultdict(list), where each input item \n",
    "#     is in the list whose key is key_fn(item)\"\"\"\n",
    "#     groups = defaultdict(list)\n",
    "#     for item in items:\n",
    "#         key = key_fn(item)\n",
    "#         groups[key].append(item)\n",
    "#     return groups\n",
    "    \n",
    "# def partition_by(inputs, attribute):\n",
    "#     \"\"\"returns a dict of inputs partitioned by the attribute\n",
    "#     each input is a pair (attribute_dict, label)\"\"\"\n",
    "#     return group_by(inputs, lambda x: x[0][attribute])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 낮은 엔트로피를 반환하는 파티션을 찾는다.\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"attribute에 따라 inputs의 파티션을 나눈다\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute] #특정 attribute의 값을 불러오고\n",
    "        groups[key].append(input) #이 input을 올바른 list에 추가 \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엔트로피를 계산\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    '''주어진 파티션에 대응되는 엔트로피를 계산'''\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961919\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "# 이제 전체 데이터셋에 대해 엔트로피를 최소화하는 파티션을 찾으면 된다.\n",
    "for key in ['level', 'lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(inputs, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.9509775004326938\n"
     ]
    }
   ],
   "source": [
    "senior_inputs = [(input, label)\n",
    "                for input, label in inputs if input['level'] == 'Senior']\n",
    "\n",
    "for key in ['lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(senior_inputs, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5. 종합하기\n",
    "> - True\n",
    "> - False\n",
    "> - (변수, 서브트리)로 구성된 tuple\n",
    "\n",
    "- True는 어떤 값을 입력 받아도 True를 반환하는 잎 노드\n",
    "- Fals는 어떤 값을 입력 받아도 False를 반환하는 잎 노드\n",
    "- tuple은 변수와 그것으로 입력값을 분류한 서브트리로 구성된 결정 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    '''의사결정나무 tree로 주어진 입력값 input을 분류하자'''\n",
    "    \n",
    "    # 잎 노드이면 값을 반환하라\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "    \n",
    "    # 그게 아니라면 데이터의 변수로 파티션을 나누자\n",
    "    # 키로 변수 값, 값으로 서브트리를 나타내는 dict를 사용하면 된다.\n",
    "    attribute, subtree_dict = tree\n",
    "    \n",
    "    subtree_key = input.get(attribute)  # 만약 입력된 데이터의 변수 중 하나가 기존에 관찰되지 않았다면 None\n",
    "    \n",
    "    if subtree_key not in subtree_dict:  # 키에 해당하는 서브트리가 존재하지 않을 때\n",
    "        subtree_key = None  # None 서브트리를 사용\n",
    "    \n",
    "    subtree = subtree_dict[subtree_key]  # 적절한 서브트리를 선택\n",
    "    return classify(subtree, input)  # 그리고 입력된 데이터를 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "    # 만약 파티션하는 첫 번째 단계라면\n",
    "    # 입력된 데이터의 모든 변수가 파티션 기준 후보\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "        \n",
    "    # 입력된 데이터에서 True와 False의 개수를 세어 본다.\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "    \n",
    "    if num_trues == 0:  # True가 없다면 False 잎을 반환\n",
    "        return False  \n",
    "    \n",
    "    if num_falses == 0:  # False가 없다면 True 잎을 반환\n",
    "        return True\n",
    "    \n",
    "    if not split_candidates:  # 만약 파티션 기준으로 사용할 변수가 없다면\n",
    "        return num_trues >= num_falses  # 다수결로 결과를 결정\n",
    "    \n",
    "    # 아니면 가장 적합한 변수를 기준으로 파티션\n",
    "    best_attribute = min(split_candidates, key=partial(partition_entropy_by, inputs))\n",
    "    \n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                     if a != best_attribute]\n",
    "    \n",
    "    # 재귀적으로 서브트리를 구축\n",
    "    subtrees = { attribute_value : build_tree_id3(subset, new_candidates)\n",
    "               for attribute_value, subset in partitions.items()}\n",
    "    \n",
    "    subtrees[None] = num_trues > num_falses  # 기본값\n",
    "    \n",
    "    return (best_attribute, subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the tree\n",
      "('level', {'Senior': ('tweets', {'no': False, 'yes': True, None: False}), 'Mid': True, 'Junior': ('phd', {'no': True, 'yes': False, None: True}), None: True})\n",
      "Junior / Java / tweets / no phd True\n",
      "Junior / Java / tweets / phd False\n",
      "Intern True\n",
      "Senior False\n"
     ]
    }
   ],
   "source": [
    "print('building the tree')\n",
    "tree = build_tree_id3(inputs)\n",
    "print(tree)\n",
    "\n",
    "print('Junior / Java / tweets / no phd', classify(tree,\n",
    "                                                 {'level' : 'Junior',\n",
    "                                                 'lang' : 'Java',\n",
    "                                                 'tweets' : 'yes',\n",
    "                                                 'phd' : 'no'}))\n",
    "\n",
    "print('Junior / Java / tweets / phd', classify(tree,\n",
    "                                               {'level' : 'Junior',\n",
    "                                                'lang' : 'Java',\n",
    "                                                'tweets' : 'yes',\n",
    "                                                'phd' : 'yes'}))\n",
    "\n",
    "print('Intern', classify(tree, {'level' : 'Intern'}))\n",
    "print('Senior', classify(tree, {'level' : 'Senior'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.6. 랜덤포레스트\n",
    "- 오버피팅을 방지할 수 있는 대표적인 방법 중 하나로 랜덤포레스트(random forests)가 있다. 한마디로 말하면 여러 개의 의사결정나무를 만들고, 그들의 다수결로 결과를 결정하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forest_classify(trees, input):\n",
    "    votes = [classify(tree, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 파티션 기준으로 사용할 변수가 얼마 남지 않았다면 전부 사용하자\n",
    "if len(split_candidates) <= self.num_split_candidates:\n",
    "    sampled_split_candidates = split_candidates\n",
    "    \n",
    "# 아니라면 랜덤한 변수를 선택\n",
    "else:\n",
    "    sampled_split_candidates = random.sample(split_candidates, self.num_split_candidates)\n",
    "    \n",
    "# 선택한 변수 중에서 가장 적절한 변수를 선택\n",
    "best_attribute = min(sampled_split_candidates, key=partial(partition_entropy_by, inputs))\n",
    "\n",
    "partitions = partition_by(inputs, best_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.7. 더 공부해 보고 싶다면\n",
    "- scikit-learn에는 많은 의사결정나무 모델이 구현되어 있다. 게다가 ensemble 모듈이 있고, 이 안에 다른 앙상블 보델을 비롯해 RandomForestClassifier이 포함되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
