---
layout: post
title: 4장~6장
date: 2023-11-24 19:20:23 +0900
category: statistics 
use_math: true
---
# 밑바닥부터 시작하는 데이터 과학  

> 4장 

데이터 시각화의 목적  
데이터 탐색, 데이터 전달
<br>  
matplotlib  
막대그래프는 이산적인 항목들에 대한 변화를 확인할 때 사용한다.  
선그래프는 경향을 볼 때 쓴다.  
산점도는 두 변수 간의 연관 관계를 보여주고 싶을 때 사용한다.  
-변수들 끼리 비교시 matplotlib은 자동으로 축의 범위를 설정한다.  
 이렇게 되면 공정한 비교를 하지 못하게 되므로 plt.axis('equal')이라는 명령을 쓰면 된다.
<br>  

> 5장

심슨의 역설  
데이터 분석을 하다보면 혼재변수(confounding variables)가 누락되어 상관관계가  
잘못 계산되는 심슨의 역설을 직면하게 된다.
<br>  
ex)동부와 서부의 데이터 과학자를 두고 어느 지역의 과학자가 친구가 더 많은지를 봤을 때  
서부는 평균친구 수가 8.2명이고 동부는 평균 친구 수가 6.5명으로 나왔다면  
서부의 과학자가 더 사교적인것이라고 볼 수 있을 것이다.  
하지만 이런 결과가 나온데에는 서부의 화창한 날씨, 느긋한 서부의 특유 문화 때문은 아닐지 의심을 해볼 수 있다.
<br>  
구체적으로 확인해본 결과 서부지역 박사 학위의 과학자는 평균 3.1명의 친구를  
동부지역의 박사학위 과학자는 평균 3.2명의 친구들을 두었다.  
그 외의 학위를 가진 서부 과학자는 평균 친구 수가 10.9명이었고,  
그 외의 학위를 가진 동부 과학자의 평균 친구 수는 13.4명이었다.  
구체적으로 학위를 두고 봤을 때 박사학위가 없는 경우 동부의 과학자의 친구가 더 많았다.  
이처럼 사용자의 학위를 고려했을 시 상관관계가 반대로 변하는 것을 확인할 수 있다.
<br>  
만약 실험을 잘 설계해 데이터의 레이블을 무작위로 설정했다면  
다른 모든 것이 동일하다는 가정은 맞아떨어질 것이다.  
하지만 다른 패턴이 존재한다면 다른 모든 것이 동일하다는 가정은 성립되지 않을 것이다.  
이런 문제를 피하기 위해선 데이터를 이해하고 변수에 영향을 주는 모든 요인을 확인하는 방법밖에 없다.  
만약 사용자들의 교육 수준에 대한 정보가 없었다면 서부의 데이터 과학자는 더 사교적이라는 결론을 내릴 수 밖에 없게된다.
<br>  
상관관계가 0이라는 것은 두 변수 사이에 선형적인 관계가 없다는 것이다.  
또한 상관관계를 통해 연관성이 얼마나 크고 작은지를 알 수 없다.
<br>   
상관관계는 인과관계를 의미하지 않는다. x와 y가 강한 상관관계를 보인다면  
X가 y를 발생시켰다고 볼 수도 있고, y가 x를 발생시켰다고 볼 수도 있다.  
혹은 서로가 서로를 동시에 발생시켰거나, 다른 외부 요인이 발생시켰거나,  
다른 인과관계가 없을 수도 있다.  
인과관계를 확인해보는 방법 중 데이터 포인트를 무작위로 선택해 확인해보는 방법이 있다.  
사용자를 비슷한 조건과 성질을 두 그룹으로 나누고 한 그룹에만 다른 요인을 적용해 본다면  
해당 요인과 결과의 인과관계를 확인해볼 수 있다.  
ex) 사용자를 대상으로 몰래 실험을 진행했을 때  
무작위로 일부 사용자를 선별해 각 사용자에게 일부 친구들의 글만 보여준다고 가정해본다.  
이 때 선별된 사용자들이 사이트에서 더 적은 시간을 보낸다면, 친구수가 증가하는 경우에  
사이트에서 보내는 시간이 증가한다는 가설이 어느정도 맞다고 볼 수 있다.
<br>  

> 6장

베이즈 정리  
사건 F가 발생했다는 가정하에 사건 E가 발생할 확률  
![참고수식](https://t1.daumcdn.net/cfile/tistory/999D963B5C09307125)  
$P(E|F)=P(E,F)/P(F)=P(F|E)P(E)/P(F)$
<br>  
$P(F)=P(F,E),P(F,!F)$  
논리 기호가 수식에서 보이지 않아서 임의로 !F로 작성  
!F는 사건 F가 일어나지 않은 경우를 의미  
!E는 사건 E가 일어나지 않은 경우를 의미
<br>  
$P(E|F)=P(F|E)P(E)/[P(F|E)P(E)+P(F|!E)P(!E)]$  
ex)10000명 중에 1명이 걸리는 질병이 있다고 할 때 질병이 있으면 양성, 없으면 음성이라고 판단하는 검사가  
99%의 경우에 대해 정확한 판단을 내린다고 가정한다.  
사건T는 양성판정, 사건 D는 질병에 걸림을 의미한다.
<br>  
양성판정을 받았을 때 실제 병에 걸린 확률은 다음과 같다.  
$P(D|T)=P(T|D)P(D)/[P(T|D)P(D)+P(T|!D)P(!D)]$  
양성판정 진짜걸림= 양성판정 진짜걸림/(양성판정 실제로 걸림+양성판정 실제로 안걸림)=양성판정 전체  
질병에 걸린 사람이 양성판정을 받을 확률 P(T|D)는 0.99  
특정 사람이 질병에 걸릴확률 P(D)는 0.00001  
질병이 없는 사람이 양성 판정을 받는 확률 P(T|!D)은 0.01  
특정 사람이 질병에 걸리지 않았을 확률 P(!D)는 0.9999  
따라서  
$P(D|T)=(0.99*0.0001)/[(0.99*0.0001)+(0.01*0.9999)]=0.009803...$  
P(D|T)는 0.98%가 된다.  
이는 양성 판정을 받은 사람들 중 실제로 질병에 걸린 사람은 1%도 안된다는 것을 의미한다.  
100만명의 사람에게 검사를 한다고 했을 때 100만명 중에 100명은 질병에 걸렸을 것이라고 예측되며  
이 중 99명은 양성판정을 받을 것이다.  
반대로 999,900명은 질병에 걸리지 않았을 것이다.  
하지만 이 중에서 9,999명은 양성 판정을 받았을 것이다.  
즉 양성 판정을 받은 (99+9,999)명 중에서 실제로 99명만 질병이 있을 것이라고 추측할 수 있다.
<br>  
이산형 분포(discrete) - 동전던지기  
연속형 분포 - 균등 분포(uniform)  
*균등분포: 0과 1사이의 모든 값에 동등한 비중을 둔 분포  
0과 1 사이에는 무한히 많은 숫자가 존재하기 때문에 숫자 하나의 비중은 0일 것이다.  
따라서 밀도 함수를 특정 구간에서 적분한 값으로 확률을 나타내는 확률밀도 함수(probability density function, pdf)로 연속 분포를 표현한다.  
균등 분포를 따르는 확률변수의 값이 0.2와 0.3 사이일 확률은 1/10이다.  
//*누적분포함수(cumulative distribution function, cdf)  
확률변수의 값이 특정 값보다 작거나 클 확률을 나타내는 함수이다.
<br>  
*정규분포  
평균인 $\mu$뮤와 $\sigma$시그마의 두 파라미터로 정의되는 종형 곡선 모양 분포이다.  
정규분포의 밀도함수  
[정규분포의 확률밀도함수 참조링크](https://www.youtube.com/watch?v=sFMjrnI93b4)  
$f(x|\mu,\sigma)=\frac{1}{\sigma\sqrt{2\pi}}exp(\frac{(x-\mu)^2}{2\sigma^2})$  
*표준정규분포  
*$\mu$는 분포의 가운데로 모평균을 의미하고, $\sigma$는 표준편차로 분포의 퍼짐 정도를 의미한다.  
$\mu$가 0이고 $\sigma$가 1인 분포를 의미한다.
<br>  
*중심극한정리  
중심극한 정리는 동일한 분포에 대한 독립적인 확률변수의 평균을 나타내는 확률변수가 대략적으로  
정규분포를 따른다는 정리이다.
<br>  
예를들어 x1,...,Xn을 평균 $\mu$와 표준편차 $\sigma$를 갖는 확률변수라고 한다.  
n이 적당히 크다면  
$\frac{1}{n}(x_1+...+x_n)$  
평균이 $\mu$이고 표준편차가 $\frac{\sigma}{n}$인 정규분포와 비슷해질 것이다.  
그렇다면 다음과 같은 수식은 대량 평균이 0이고 표준편차가 1인 정규분포와 비슷해질 것이다.  
$\frac{(x_1+...+x_n)-\mu n}{\sigma \sqrt{n}}$
<br>  
이항 확률변수 예시  
이항확률변수는 n과 p 두가지 파라미터로 구성된다.  
이항 변수는 단순히 n개의 독립적인 베르누이 확률변수를 더한 것이다.  
각 베르누이 확률변수의 값은 p의 확률로 1, 1-p의 확률로 0이 된다.
<br>  
베르누이 확률변수의 평균은 p이며 표준편차는 $\sqrt{p(1-p)}$이다.  
중심극한 정리는 n이 적당히 크다면 이항 확률변수는 대략 평균이 $\mu=np$이고  
표준편차가 $\sigma = \sqrt{np(1-p)}$인 정규분포 확률변수와 비슷해진다는 것을 알려준다.
<br>  
평범한 동전을 100번 던져서 앞면이 60번 이상 나올 확률을 알고 싶다고 할 때.  
중심극한정리의 핵심은 이 확률을 (평균이 50이고 표준편차가 5인)정규분포의 확률변수가 60보다 클 확률로 근사할 수 있다는 점이다.
<br>  
참고출처:  
https://velog.io/@skyepodium/%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC  

