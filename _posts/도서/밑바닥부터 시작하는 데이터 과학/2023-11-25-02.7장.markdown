---
layout: post
title: 7장
date: 2023-11-25 19:20:23 +0900
category: statistics 
use_math: true
---
# 밑바닥부터 시작하는 데이터 과학  

> 7장

가설과 추론  

동전던지기 예시  
앞면이 나올 확률 p,  
동전이 공평하다는 의미의 p=0.5이다(귀무가설), p!=0.5(대립가설)  
동전을 n번 던져 앞면이 나온 횟수 X
<br>  
동전던지기는 베르누이 분포를 따를 것이다.(=X가 이항분포를 따르는 학률변수다.)  
이항분포는 정규분포로 근사할 수 있다.
<br>  
누적분포함수는 확률변수가 특정값보다 작을 확률을 나타낸다.  
만약 확률변수가 특정 값보다 작지 않으면, 특정 값보다 크다는 것을 의미한다.  
만약 확률변수가 범위 밖에 존재한다면 범위 안에 존재하지 않음을 의미한다.  
<br>  
확률이 주어졌을 때 평균을 중심으로 하는 대칭적인 구간을 구할 수도 있다.  
예를들어 분포의 
%를 차지하는 평균 중심의 구간을 구하고자 한다면 양쪽 꼬리부분이 각각 분포의 
%를 차지하는 지점을 구하면 된다.  
<br>  
유의수준:1종 오류를 얼마나 허용해줄 것인지를 의미한다.  
1종오류: 귀무가설이 참인데 기각하는 오류이다.
<br>  
대립가설: 앞면이 나올 확률이 p라고 할 때 동전이 공평하다는 의미의 p!=0.5  
x가 주어진 범위를 벗어나면 귀무가설을 기각하는 가설검정
<br>  
X가 주어진 범위를 벗어나면 귀무가설을 기각하는 가설검증으로 평균은 0이고 표준편차가 1인 누적분포함수에서  
유의수준 0.05기준 P(Z <= z) = probability인 z값을 반환해 
p가 정말 0.5(=귀무가설이 참이라면) X가 주어진 범위를 벗어날 확률은 5%에 안될 것이다.  
만약 귀무가설이 참이라면 이 가설검정은 20번 중 19번은 올바른 결과를 줄 것이다.
<br>  
2종 오류를 범하지 않을 확률인 검정력은 귀무가설이 거짓이지만 이를 채택하는 오류이다.  
제 2종 오류를 측정하기 위해선 귀무가설이 거짓이라는 것이 무엇을 의미하는지를 알아야 한다.(p가 0.5가 아니라는 말은 X의 분포에 대해 많은 것을 알려주지 않는다.)
<br>  
p<=0.5, 동전이 앞면에 편향되지 않은 경우를 귀무가설로 정한다면 X가 50보다 크면 귀무가설을 기각하고  
50보다 작다면 기각하지 앟ㄴ는 단측검정이 필요해진다.  
유의 수준이 5%인 가설검정을 위해선 분포의 95%가 해당 값 이하인 경계값을 찾을 수 있다.
<br>  

> p-value

p-value: 어떤 확률값을 기준으로 구간을 선택하는 대신 귀무가설이 참이라고 가정하고 실제로  
관측된 값보다 더 극단적인 값이 나올 확률을 구하는 것이다.  
양측검정을 수행해 동전의 앞면이 나온 경우가 530번 관측되어 p-value가 0.062가 나왔다면  
p-value가 5%보다 크기 때문에 귀무가설을 기각하지 않는다.  
만약 동전의 앞면이 532번이 나왔다면 p-value는 5% 보다 작을 것이고, 이 경우  
귀무가설을 기각할 것이다.
<br>  
!양측검증시 기준이 되는 값을 530으로 두지 않고 539.5를 사용한 이유  
연속성 수정(continuity correction) 때문이다.  
*연속성 수정: 이산형 분포를 연속형 분포로 근사시킬때 약간의 수정을 하는 것이다. [참고링크](http://contents.kocw.or.kr/KOCW/document/2013/DonggukGyeongju/ShimKyubark/5.pdf)  
이항분포는 이산형이고 정규분포는 연속형이므로 이산적으로 주어진 구간을 정규분포에 맞게 조정해야할 필요가 있기 때문이다.  
이는 정수값을 연속적인 값으로 대응시켜 확률을 구해야 오차의 한계를 줄일 수 있기 때문이다.  
이항확률변수를 정규확률변수로 연속성을 수정하기 위해서 일반적으로 0.5를 빼주거나 더해준다.  
(이항확률변수가 a에서 b사이에 있을 확류을 구할 때 정규확률변수로 대응시  
a-0.5,b+0.5로 값을 대응시켜줘야 한다.)  

> 신뢰구간

앞에서 p는 앞면이 나올 미지의 분포를 나타내는 파라미터였다.  
만약 사건에 대한 분포를 모른다면 관측된 값에 대한 신뢰구간을 사용해 가설을 검증할 수 있다.  
ex) 공평하지 않은 동전에 대한 확률을 앞면이면 1, 뒷변이면 0인 베르누이 확률변수의 평균을 이용해 추정할 수 있다.  
만약 동전을 천번던져 앞면이 525번 나왔다면 p는 0.525로 추정할 수 있을 것이다.  
그렇다면 이 추정값에 대해 얼마나 신뢰할 수 있을까?  
만약 p의 정확한 값을 알고 있다면 중심극한정리를 사용해 베르누이 확률변수들의 평균은 대략 평균이 p이고 표준편차가 다음과 같은 정규분포로 추정할 수 있을 것이다.  
math.sqrt(p * (1-p)/1000)  
만약 p값을 모를 경우 추정치를 사용할 수 있다.  
p_hat=525/1000  
mu=p_hat  
sigma = math.sqrt(p_hat * (1-p_hat) / 1000)  
정규분포의 근사를 사용하면 진짜 p가 다음 구간 안에 포함되어 있을 것이라고 95% 확신할 수 있을 것이다.  
normal_two_sided_bounds(0.95, mu, sigma)  
!실험을 수 없이 반복하면, 전체 실험의 95%에서는 진짜 파라미터 p가(진짜 파라미터 p는 매번 동일)  
관측된 신뢰구간(신뢰구간은 매번 다를 수도 있다) 사이에 존재할 것이다.
<br>  
앞면이 525번 나왔을 때 양측검증을 시행해 0.4940, 0.556이 나왔다고 한다면  
0.5는 신뢰구간 안에 있으므로 동전은 공평하다고 결론을 내릴 수 있다.  
반대로 앞면이 450번 나왔을 때 sigma는 0.0158이고, 양측검증시 0.5091, 0.5709가 나왔다면  
공평한 동전에 대한 확률은 계산된 신뢰구간 밖에 존재해 가설이 참이라면 모든  
경우의 95%에 대해 참인 가설검정을 통과하지 못하게 된다.  

> p value 해킹

귀무가설을 잘못 기각하는 경우가 5%인 가설검정은 정의에서 알 수 있듯이 모든 경우의  
5%에서 귀무가설을 잘못 기각한다.  
이는 의미있는 결과를 찾으려 노력한다면 보통 의미있는 결과를 찾을 수 있다는 것을 의미한다.  
하지만 p value의 관점에서 추론을 하면 p value 해킹이 발생할 수 있다.  
*p 해킹: 유의한 통계수준(p value를 0.05 이하)로 만들기 위해 일부 이상치를 살리거나 버리는 등의 조작을 통해  
데이터 획득과정에서 임의로 멈추거나 데이터 분석 방법을 임의대로 다양하게  
변화시키거나 데이터 구조를 변화시키는 것이다.
<br>  
데이터 과학을 제대로 하기 위한 원칙  
-가설은 데이터를 보기전에 세운다.  
-데이터를 전처리할 때에는 세워둔 가설을 잠시 잊는다.  
-p value는 전부가 아니다.  
<br>  

> A/B 테스트 해보기 예시 

A:맛이 끝내줘요! B:편견이 없어요! 라는 문구가 있다.  
사용자에게 임의로 두 개의 광고 중 하나를 보여주고 실제로 광고를 클릭하는 사용자의 수를  
살펴보는 실험을 진행하기로 했다.  
만약 광고 A를 본 1000명 중 990명이 광고를 클릭했고 광고 B를 본 1000명 중 10명만이 광고를 클릭했다면  
광고 A가 더 좋은 광고라고 볼 수 있지만 이 차이가 면확하지 않다면?  
이 때 통계적 추론을 사용한다.  
N_A명의 사용자가 광고 A를 보았고 그 중 n_A명이 광고를 클릭했다고 본다.  
이는 베르누이 시행으로 볼 수 있을 것이다. 각 사용자가 광고 A를 클릭할 확률을 p_A라고 정의한다.  
만약 N_A가 큰 숫자라면 n_A/N_A는 평균이 p_A이고 표준편차가 math.sqrt(p_A(1-p_A)/N_A)인 정규분포에 근접할 것이다.  
비슷하게 n_B/N_B는 평균이 p_B이고 표준편차가 math.sqrt(p_B(1-p_B)/N_B)인 정규분포에 근접할 것이다.  
만약 두 정규분포가 독립이라면(각 베르누이 시행은 독립적인 시행이기 때문에 적절한 가정이다.)  
두 정규분포의 차이 또한 평균이 p_B-p_A이고 표준편차가 math.sqrt((sigma_A)^2+(sigma_B)^2)인 정규분포를 따른다.  
!지금 예시는 편법이다. 원래 표준편차를 미리 알고 있어야 한다.  
지금 예시는 표준편차를 데이터에서 추정하기 때문에 원래 t분포를 사용해야 한다.  
하지만 주어진 데이터가 많다면 차이가 별로 크지 않으므로 정규분포를 사용해도 된다.  
p_A와 p_B가 같다는(=p_A-P-B는 0이다.) 귀무가설을 검증해봤을 때  
1000명 중 200명이 A광고를 클릭했고, 1000명 중 180명이 B 광고를 클릭했다면  
z=-1.14가 나온다.  
*z 점수는 평균으로부터 몇 SD 큰지, 작은지를 나타낸다.  
만약 두 분포의 평균이 같다면 이렇게 큰 차이가 발생할 확률은 0.254(양측검정 p value)가 된다.  
이는 값이 크기때문에 두 분포가 다르다고 결론을 내릴 수 없다.  
만약 150명이 편견이 없다는 광고를 클릭했다면 z는 -2.94, 양측검정의 p value는 0.003이 나왔다.  
이는 두 광고가 동일하게 효과적이라면 이렇게 큰 차이가 발생할 확률은 0.003이라는 의미이다.  
<br>  
*정규 분포 두 개가 독립적인지 확인하는 방법  
-공분산이 0  
공분산을 검사해 두 변수의 공분산이 0이라면 두 변수가 서로 독립적이라고 볼 수 있다.  
이 때 충족해야 하는 조건이 있다.  
결합 확률밀도함수 fX,y(x,y)=fX(x)*fY(y)  
여기서 fX,Y(x,y)는 두 변수의 결합 확률밀도함수이고, fX(x)와 fY(y)는 각각 개별 변수의 확률밀도함수이다.  
이 식이 성립하면 두 변수가 독립적이라고 볼 수 있다.  
-상관계수가 0  
두 변수가 결합 정규 분포를 가지고 있다면 상관계수가 0일 때 독립성이 성립한다.  
이는 공분산이 0이고 두 변수간 선형 상관이 없음을 의미한다.  
<br>  

> 베이지안 추론 92p

앞서 귀무가설이 사실이라면 이렇게 극단적인 통계치가 발생할 확률은 3%이다 같은 예시를 보았다.  
이밖에 알려지지 않은 파라미터를 확률변수로 보는 방법이 있다.  
파라미터에 대한 사전분포가 주어지고, 관측된 데이터와 베이즈 정리를 사용해 사후분포를 갱신할 수 있다.  
통계적 검정에 대해 확률적으로 결론을 내는 대신 파라미터에 대해 확률적으로 결론을 낼 수 있다.
<br>  
동전던지기 예시처럼 알려지지 않은 파라미터가 확률이라고 했을 때  
모든 확률값이 0과 1 사이에서 정의되는 베타분포를 사전분포로 사용한다.  
예를들어 알파와 베타가 모두 1이라면(중심이 0.5이고 매우 퍼진) 균등분포가 될 것이다.  
* [베타분포 참고](https://losskatsu.github.io/statistics/betadist/#1-%EB%B2%A0%ED%83%80%EB%B6%84%ED%8F%AC%EC%9D%98-%EC%A0%95%EC%9D%98)
만약 알파가 베타보다 훨씬 크면 대부분의 밀도는 1 근처에 있을 것이다.  
반대로 알파가 베타보다 훨씬 작다면 대부분의 밀도는 0 근처에 있을 것이다.
<br>  
p에 대한 사전확률을 가정할 때 동전이 공평한지 아닌지 어떤 입장을 취하고 싶지 않다면  
알파와 베타 모두 1로 가정할 수 있다. 앞면이 55%의 경우로 발생한다고 믿는다면  
알파를 55, 베타를 45로 가정할 수 있다.  
동전을 여러번 던져 앞면이 h번, 뒷면이 t번 나왔을 때 p의 사후확률은 알파+h와 베타+t에 대한 베타분포이다.  
이항분포에서 관측된 데이터로 베타분포를 따르는 사전분포를 갱신한다면 계산되는 사후분포 또한  
베타분포를 따른다.
<br>  
참고출처:  
https://github.com/ranisop/Data_Science_From_Scratch/blob/master/ch07_hypothesis_and_inference.ipynb  
https://velog.io/@skyepodium/%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC  
http://contents.kocw.or.kr/KOCW/document/2013/DonggukGyeongju/ShimKyubark/5.pdf  
https://m.blog.naver.com/fastwalker/30161834330  
https://en.wikipedia.org/wiki/Data_dredging  
chat-GPT  
