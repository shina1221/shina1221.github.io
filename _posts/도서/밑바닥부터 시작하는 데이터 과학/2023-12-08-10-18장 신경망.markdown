---
layout: post
title: 18장
date: 2023-12-10 19:20:23 +0900
category: ML 
use_math: true
---
# 밑바닥부터 시작하는 데이터 과학  

인공신경망: 뇌를 묘사한 예측모델이다. 대부분의 신경망 모델은 블랙박스이기 때문에 이해도 어렵고,  
큰 신경망은 학습시키기도 어렵기 때문에 초보 데이터 과학자가 문제를 해결할 대 활용하기에 좋은 방법은 아니다.  

> 퍼셉트론

n개의 이진수(binary)가 하나의 뉴런을 통과해 가중합이 0보다 크면 활성화되는 가장 간단한 신경망 구조이다.  
퍼셉트론은 간단히 초평면으로 구분되는 두 개의 공간을 분리시키는 역할을 한다.  
weight만 잘 선택하면 퍼셉트론으로도 여러가지 간단한 문제를 풀 수 있다. 하지만 단일 퍼셉트론만으로는  
둘 중 하나의 입력값만 1일 때 1을 반환하고 다른 모든 경우에는 0을 반환하는 XOR 게이트를 만들 수 없다.
<br>  

> 순방향(feed forward) 신경망

보통은 입력값을 받고 그대로 다음 층으로 값을 전송하는 입력층,  
하나 이상의 은닉승, 그리고 최종값을 반환하는 출력층 등으로 구성된다.  
은닉층(들)은 직전층의 출력값을 입력받아 어떤 계산을 하고 다음 층으로 전달하는 역할을 한다.  
퍼셉트론과 마찬가지로 입력층에 속하지 않은 각 뉴런에는 각 weight와 bias가 할당된다.  
또 각 뉴런은 퍼셉트론과 마찬가지로 입력값과 weight의 곱을 계산한다.
<br>  

> backpropagation(역전파)

신경망을 학습시킬 때 흔히 사용되는 방법으로는 backpropagation(역전파)이 있다.  
backpropagation은 경사하강법과 상당히 유사하다.  
1.입력 벡터에 대해 feed_forward를 수행하고 모든 뉴런의 출력값을 계산한다.  
2.각 뉴런에 대해 오류값, 즉 결과값과 실제 target값의 차이를 계산한다.  
3.weight에 따라 오류값의 gradient를 계산해 오류를 최소화하는 방향으로 weight를 재조정한다.  
4.은닉증의 오류값을 추정하기 위해 출력 층의 오류값을 뒤로 전파(propagate)한다.  
5.오류값의 기울기를 다시 구하고 같은 방식으로 은닉층의 weight를 재조정한다.  
