---
layout: post
title: 17장
date: 2023-12-09 19:20:23 +0900
category: ML 
use_math: true
---
# 밑바닥부터 시작하는 데이터 과학  

> 의사결정나무란

이해하기 쉽고, 예측시숫자형 데이터와 범주형 데이터를 동시에 다룰 수 있다.  
또한 특정 변수의 값이 누락되어도 사용할 수 있다.  
하지만 학습ㄷ ㅔ이터에 대해 최적의 의사결정나무를 찾는것은 어렵다.  
의사결정나무는 새로운 데이터에 대한 일반화 성능이 좋지않게 오버피팅되기 쉽다..  
의사결정나무는 범주형 결과를 반환하는 분류나무와 숫자형 결과를 반환하는 회귀나무로 나뉜다.
<br>  

> 엔트로피

의사결정나무를 만들기 위해선 어떤 질문을 던질 것이고, 어떤 순서로 질문할 것인지를 정해야한다.  
이상적으로 예측하려는 대상에 대해 가장 많은 정보를 담고 있는 질문을 고르는 것이 좋다.  
**얼마만큼의 정보를 담고 있는가를 엔트로피라고 한다.**  
ex)데이터셋 S가 있고 각 데이터 포인트 c1,c2,...cn등은 유한개의 클래스 중 하나에 속한다고 한다.  
모든 데이터 포인트가 단 하나의 클래스에 속한다면 사실 불확실성은 전혀없고 엔트로피도 낮다.  
반면 모든 데이터 포인트가 모든 클래스에 고르게 분포해있다면 엔트로피는 높다고 할 수 있다.  
수학적 개념)  
한 데이터 포인트가 클래스 $c_i$클래스에 속할 확률은 $p_i$이다.  
![수식1](https://latex.codecogs.com/svg.image?&space;H(S)=-p_1log_2p1-...-p_nlog_2p_n)  
각 항 $-p_i,log_1p_i$는 항상 0보다 크거나 같고 $p_i$의 값이 0또는 1에 가까울 때 0에 가까워진다.  
![엔트로피]()
모든 $p_i$rk 0혹은 1에 가까우면 (대부분의 데이터 포인트가 하나의 클래스에 속하면)엔트로피는 아주 작을 것이다.  

> 파티션의 엔트로피 

앞서 데이터셋 전체에 대한 엔트로피를 계산했다.  
하지만 의사결정나무의 각 단계는 데이터를 여러개의 파티션으로 분할하기 때문에 데이터가 여러개의 작은 데이터셋으로 나뉜다.  
이에 따라 하나의 데이터셋을 여러개의 파티션으로 나누더라도 데이터셋 전체에 대한 엔트로피를 계산할 수 있는 방법이  
필요해졌다.  
이 때 파티션 하나하나가 낮은 엔트로피를 가지는 경우 전반적인 엔트로피도 낮고, 파티션 각각이 높은 엔트로피를  
가지는 경우에는 전반적인 엔트로피도 높아야 할 것이다.  
수학적 개념)  
데이터 S를 $q_1,...,q_m$의 비율을 가지는 파티션 $S_1,...S_m$으로 나누는 경우에 엔트로피는 가중합으로 구한다.  
![엔트로피 가중합](https://latex.codecogs.com/svg.image?H=q_1H(S_1)&plus;...&plus;q_mH(S_m))  
이 접근법의 한가지 문제는 다양한 값을 가질 수 있는 변수를 사용해 파티션을 나눌 경우  
오버피팅이 되어 엔트로피가 낮아진다는 것이다.  
ex)은행 고객들이 대출을 잘 갚을 수 있을 것인지에 대해 의사결정나무를 만들려할 때  
변수 중 고객들의 주민등록변호가 담겨있는 변수가 있는데 이 변수로 파티션을 나누게 되면 파티션당  
한 명식만 속하게 되어 엔트로피가 모두 0이되지만 이렇게 파티션이 나뉘면 학습데이터 외의 데이터를  
잘 처리할 수 없을 것이다.  
따라서 **의사결정나무를 사용할 때에는 다양한 값을 가질 수 있는 변수들의 경우를 최대한 피하거나,**  
**변수에 속한 값을 적은 수의 버킷으로 나눠 선택 가능한 값의 종류를 줄이는 것이 좋다.**  
<br>

> 의사결정나무 만들기 


참고출처:  
